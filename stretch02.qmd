---
title: "Stretch02 (Assignment07)"
author: "Huixin Cai & Ming Zhou"
format: html
editor: source
warning: false
self-contained: true
---
## 1 Set up
**a. Data**
Our goal is to use individuals' social and economic characteristics (e.g. gender, age, education, race, social assistance, SNAP benefits, etc.) to predict individuals' employment status. The employment status - A_EXPLP is our target variable, which is a categorical variable with 3 values (0 for not in universe,1 for employed, 2 for unemployed). 
The data is Annual Social and Economic (ASEC) Supplement. It provides the usual monthly labor force data, but in addition, provides supplemental data on work experience, income, non-cash benefits, and migration. Comprehensive work experience information is given on the employment status, occupation, and industry of persons 15 years old and above.
```{r}
library(tidyverse)
library(lubridate)
library(dplyr)
data <- read_csv("Data/pppub22.csv")
data1 <- data %>%
  select(A_EXPLF,MIG_REG, SPM_NUMKIDS, SPM_ACTC, SPM_BBSUBVAL,
         SPM_FAMTYPE, SPM_CAPHOUSESUB, SPM_CAPWKCCXPNS, SPM_CHILDCAREXPNS,
         A_HGA, SPM_CHILDSUPPD, SPM_EITC, A_MARITL, HEA, SPM_FEDTAX, SPM_GEOADJ,
         SPM_ENGVAL, PRDTRACE, PHIP_VAL, MCAID, NOW_MCAID, NOW_DEPNONM,
         NOW_MRKUN, MRKUN, NOW_MRK, MRK, NOW_DIR, OWNDIR, COV, COV_CYR, AGI, 
         EIT_CRED, CHSP_VAL, CSP_VAL, PAW_VAL, RINT_SC2, RINT_VAL1, PTOTVAL, DIS_HP,
         DIS_CS, DIS_CS, DIS_YN, DIV_YN, DSAB_VAL, PEARNVAL, EARNER, LKWEEKS,
         LOSEWKS) 
data1$A_EXPLF <- as.factor(data1$A_EXPLF)
```
**b. Split the data**
````{r}
library(tidymodels)
set.seed(20221111)
split <- initial_split(data = data1, prop = 0.8)
data_training <- training(x = split)
data_testing <- testing(x = split)
```
**c. Exploratory data analysis**
```{r}
library(dplyr)
library(ggplot2)
# Take a overview of the data 
glimpse(data_training)
# The Distribution of the dependent variable (individuals' employment status)
data_training %>%
  filter(complete.cases(.)) %>%
  ggplot(aes(x=A_EXPLF)) +
  geom_bar(aes(fill=factor(A_EXPLF))) +
  scale_fill_discrete(labels=c('not in the labor force', 
                               'employed',
                               'unemployed')) +
  labs(y = "The number of individuals",
       x = "The employment status",
       title = paste0("Half of individuals are not in the labor force,",
       "while the unemployment rate is about 3.3%"), 
       fill = "Individuals' unemployment status",
       caption = "Source: census.gov")
# The Distribution of the regressors and controlled variables 
summary(data_training)
```
**d. Explicitly pick an error metric**
False negative has higher cost (the person is unemployed but the model predicts them to be employed, in that way the budget for unemployment compensation provided by the government would not be enough), while false positive would lead to excessive budget, which does less harm.

## 2 Come up with Models & 3 Estimation 
```{r}
library(tidymodels)
#Build a recipe 
data_rec <- recipe(A_EXPLF~ ., data = data_training) %>%
  # center and scale all predictors
  step_normalize(all_predictors()) %>%
  step_corr(all_predictors())
```
**KNN**
```{r}
knn_mod <- nearest_neighbor(neighbors = 8) %>%
  set_engine(engine = "kknn") %>%
  set_mode(mode = "classification")

knn_workflow <- 
  workflow() %>%
  add_model(spec = knn_mod) %>%
  add_recipe(recipe = data_rec)

knn_fit <- knn_workflow %>%
  fit(data = data_training)

# fit to training data
predictions_KNN  <- bind_cols(
  data_training,
  predict(object = knn_fit, new_data = data_training),
  predict(object = knn_fit, new_data = data_training, type = "prob"))

select(predictions_KNN, A_EXPLF, starts_with(".pred"))
```
**Decision Tree**
```{r}
tree_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")

tree_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(tree_mod)

tree_fit <- tree_wf %>%
  fit(data = data_training)

# fit to training data
predictions_tree  <- bind_cols(
  data_training,
  predict(object = tree_fit, new_data = data_training),
  predict(object = tree_fit, new_data = data_training, type = "prob"))

select(predictions_tree, A_EXPLF, starts_with(".pred"))

cm_tree <- conf_mat(data = predictions_tree,
               truth = A_EXPLF,
               estimate = .pred_class)
cm_tree

# fit to testing data
predictions_tree_test <- bind_cols(
  data_testing,
  predict(object = tree_fit, new_data = data_testing),
  predict(object = tree_fit, new_data = data_testing, type = "prob"))

select(predictions_tree, A_EXPLF, starts_with(".pred"))

cm_tree_test <- conf_mat(data = predictions_tree_test,
               truth = A_EXPLF,
               estimate = .pred_class)
cm_tree_test
```

**Linear Regression** 
```{r}
show_engines('multinom_reg')
library(nnet)
folds <- vfold_cv(data = data_training, v = 10)

lm_mod <- 
  multinom_reg(penalty = 1) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

lm_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(lm_mod) 

lm_cv <- lm_wf %>%
  fit_resamples(resamples = folds)

# select the best model based on the "accuracy" metric
lm_best <- lm_cv %>%
  select_best(metric = "accuracy")

# to update (or "finalize") your workflow by modifying the line below
lm_final <- 
  finalize_workflow(lm_wf,
                    parameters = lm_best)

lm_fit <- lm_final %>%
  fit(data = data_training)

# fit to all training data
predictions_lm  <- bind_cols(
  data_training,
  predict(object = lm_fit, new_data = data_training),
  predict(object = lm_fit, new_data = data_training, type = "prob"))

select(predictions, A_EXPLF, starts_with(".pred"))

cm_lm <- conf_mat(data = predictions_lm,
               truth = A_EXPLF,
               estimate = .pred_class)
cm_lm

# fit to testing data
predictions_lm_test  <- bind_cols(
  data_testing,
  predict(object = lm_fit, new_data = data_testing),
  predict(object = lm_fit, new_data = data_testing, type = "prob"))

select(predictions_lm_test, A_EXPLF, starts_with(".pred"))

cm_lm_test <- conf_mat(data = predictions_lm_test,
               truth = A_EXPLF,
               estimate = .pred_class)
cm_lm_test
```

## 4 Interpretion 
**a**
None of our models have been able to predict anybody unemployed properly, which is the category that we care the most about. Our plan is to use this model to find those unemployed as the target group of some government compensatory program, so for now our models are not effective.

**b**
1. We may want to recategorize our core outcome variable into a binary variable, with 0 for "not in labor force" and 1 for "in labor force", or with 0 for "employed" and 1 for "unemployed" and get rid of the observations that are not in universe.

2. Since our data set has so many variables, we can try using PCA or other methods we learned in class to narrow down the number of variables, instead of manually choosing variables.

3. As we are using survey data, and our data set is pretty unbalanced, we need to find a way to properly weigh our variables.