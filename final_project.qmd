---
title: "PPOL670 Final Project"
author: "Ming Zhou & Huixin Cai"
format: html
editor: source
editor_options: 
  chunk_output_type: console
warning: false
self-contained: true
---
# Data Loading
```{r set_up}
# load data
library(tidyverse)
library(lubridate)
library(dplyr)
library(tidymodels)
library(tidyclust)
library(factoextra)
library(broom)
library(ggplot2)
data <- read_csv("Data/pppub22.csv") %>%
  select(A_EXPLF,MIG_REG, SPM_NUMKIDS, SPM_ACTC, SPM_BBSUBVAL,
         SPM_FAMTYPE, SPM_CAPHOUSESUB, SPM_CAPWKCCXPNS, SPM_CHILDCAREXPNS,
         A_HGA, SPM_CHILDSUPPD, SPM_EITC, A_MARITL, HEA, SPM_FEDTAX, SPM_GEOADJ,
         SPM_ENGVAL, PRDTRACE, PHIP_VAL, MCAID, NOW_MCAID, NOW_DEPNONM,
         NOW_MRKUN, MRKUN, NOW_MRK, MRK, NOW_DIR, OWNDIR, COV, COV_CYR, AGI, 
         EIT_CRED, CHSP_VAL, CSP_VAL, PAW_VAL, RINT_SC2, RINT_VAL1, PTOTVAL, DIS_HP,
         DIS_CS, DIS_CS, DIS_YN, DIV_YN, DSAB_VAL, PEARNVAL, EARNER, LKWEEKS, LOSEWKS,
         AGE1) %>%
  #exclude observations with missing answers
  filter(complete.cases(.)) %>%
  #only include observations in the labor force (15-64)
  filter(AGE1 > 14 & AGE1 < 65)

# create new variable "in_labor"
# If in the labor force, in_labor equals 1. 
# If in the labor force, in_labor equals 1. 
data <- data %>%
  mutate(in_labor = 
           if_else(A_EXPLF == 0,0,1)) %>%
  select(-A_EXPLF)

data$in_labor <- as.factor(data$in_labor)
```
## Supervised modeling without Dimension Reduction 
*Split data*
```{r Split_data}
split_data <- initial_split(data = data, prop = 0.8)
data_training <- training(x = split_data)
data_testing <- testing(x = split_data)
```
*EDA*
```{r}

```
*Cross validation* 
```{r Cross_validation}
set.seed(20221111)
folds <- vfold_cv(data = data_training_pca, v = 10)
```
*Recipe*
```{r Recipe}
data_rec <- recipe(in_labor~., data = data_training) %>%
  # center and scale all predictors
  step_normalize(all_predictors()) %>%
  step_corr(all_predictors())
```

## logistic model: all models failed
```{r}
lm_mod <- 
  logistic_reg(penalty = 1) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

lm_w <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(lm_mod) 

lm_cv <- lm_wf %>%
  fit_resamples(resamples = folds)

# select the best model based on the "accuracy" metric
lm_best <- lm_cv %>%
  select_best(metric = "accuracy")

# to update (or "finalize") your workflow by modifying the line below
lm_final <- 
  finalize_workflow(lm_wf,
                    parameters = lm_best)

lm_fit <- lm_final %>%
  fit(data = data_training)

# fit to all training data
predictions_lm  <- bind_cols(
  data_training,
  predict(object = lm_fit, 
          new_data = data_training),
  predict(object = lm_fit, 
          new_data = data_training, type = "prob"))

cm_lm <- conf_mat(data = predictions_lm,
               truth = in_labor,
               estimate = .pred_class)
cm_lm
```

## LASSO model 
```{r}
# create a tuning grid for lasso regularization, varying the regularization penalty
lasso_grid <- grid_regular(penalty(), levels = 10)

# create a linear_regression model so that you can tune the penalty parameter
lasso_mod <- linear_reg(
  penalty = tune(), 
  mixture = 1
) %>%
  set_engine("glmnet") 

# create a workflow 
lasso_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(lasso_mod) 

# perform hyperparameter tuning 
lasso_cv <- lasso_wf %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid
  )

# select the best model based on the "rmse" metric
lasso_best <- lasso_cv %>%
  select_best(metric = "rmse")

# finalize the workflow 
lasso_final <- finalize_workflow(
  lasso_wf,
  parameters = lasso_best
)

# fit to the training data and extract coefficients
lasso_fit <- lasso_final %>%
  fit(data = data_training) 

#make predictions
predictions_lasso  <- bind_cols(
  data_training,
  predict(object = lasso_fit, 
          new_data = data_training),
  predict(object = lasso_fit, 
          new_data = data_training, type = "prob"))

cm_lasso <- conf_mat(data = predictions_lasso,
               truth = in_labor,
               estimate = .pred_class)
```
## Decision Tree 
```{r}
tree_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")

tree_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(tree_mod)

tree_fit <- tree_wf %>%
  fit(data = data_training)

# fit to training data
predictions_tree  <- bind_cols(
  data_training,
  predict(object = tree_fit, 
          new_data = data_training),
  predict(object = tree_fit, 
          new_data = data_training, 
          type = "prob"))

select(predictions_tree, in_labor, starts_with(".pred"))

cm_tree <- conf_mat(data = predictions_tree,
               truth = in_labor,
               estimate = .pred_class)
cm_tree
```
## Random Forest 


# Dimension Reduction
## Decide the number of principle components
```{r The_number_of_PC}
library(factoextra)
# scale data sets
data1 <- data1 %>%
  mutate_all(~(scale(.) %>% as.vector))
# create PCA
pca_1 <- prcomp(data1, scale = TRUE)
#create scree plot to decide how many principal components to retain 
screeplot(pca_1, type="lines")
```
The scree plot occurs at component 4, which is the “elbow” of the scree plot. Therefore, it cound be argued based on the basis of the scree plot that **the first three components** should be retained.

## Dimension Reducation with PCA
```{r Dimension_reduction}
# select all numeric variables
data2 <- data %>%
  select(-A_EXPLF)
#Cross Validation 

# create a recipe with no outcome variable and all predictors
preprocess_rec <- recipe(~ ., data = data2) %>%
  step_zv(all_predictors()) %>%
  # center and scale (normalize) all predictors
  step_normalize(all_numeric_predictors())%>%
  # perform pca and use num_comp = 3 to only keep three components
  step_pca(all_numeric(),num_comp = 3) %>%
  # run prep to prepare recipe
  prep()

# obtain summary metrics (use number = 3)
tidy(preprocess_rec, number = 3, type = "variance")

# obtain loadings (use number = 3)
tidy(preprocess_rec, number = 3, type = "coef")

# apply recipe to data
processed_data <- preprocess_rec %>%
  bake(new_data = data2)

#combine variables
data_pca <- cbind(
  data$A_EXPLF, processed_data
)

# rename variable "data$A_EXPLF"
data_pca <- rename(data_pca,
       "A_EXPLF" = "data$A_EXPLF")

```

# Supervised Modeling
## Split data 
```{r Split_data}
set.seed(20221111)
split_pca <- initial_split(data = data_pca, prop = 0.8)
data_training_pca <- training(x = split_pca)
data_testing_pca <- testing(x = split_pca)
```

## Exploratory data analysis 
```{r Exploratory_data_analysis}
#correlation - PCA
#
data_training_pca %>%
  ggplot(aes(x=in_labor)) +
  geom_bar(aes(fill=in_labor)) +
  scale_fill_discrete(labels=c('not in the labor force', 
                               'in the labor force')) +
  scale_x_discrete(labels = c('not in the labor force',
                              'in the labor force')) +
  labs(y = "The number of individuals",
       x = "Whether in the labor force or not", 
       title = "Nealy 1/3 of working population are not in the labor force", 
       fill = "Whether in the labor force or not",
       caption = "Source: census.gov")
```

## Create Recipe
```{r}
#Build a recipe 
data_rec_pca <- recipe(in_labor~PC1+PC2+PC3, data = data_training_pca) %>%
  # center and scale all predictors
  step_normalize(all_predictors()) %>%
  step_corr(all_predictors())
```

## Decision Tree 
```{r decision_tree}
tree_mod_pca <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")

tree_wf_pca <- workflow() %>%
  add_recipe(data_rec_pca) %>%
  add_model(tree_mod_pca)

tree_fit_pca <- tree_wf_pca %>%
  fit(data = data_training_pca)

# fit to training data
predictions_tree_pca  <- bind_cols(
  data_training_pca,
  predict(object = tree_fit_pca, 
          new_data = data_training_pca),
  predict(object = tree_fit_pca, 
          new_data = data_training_pca, 
          type = "prob"))

select(predictions_tree_pca, in_labor, starts_with(".pred"))

cm_tree_pca <- conf_mat(data = predictions_tree_pca,
               truth = in_labor,
               estimate = .pred_class)
cm_tree_pca

#create decision tree graph 
rpart.plot::rpart.plot(x = tree_fit_pca$fit$fit$fit)
```

## Logistic Regression 
```{r}
show_engines('logistic_reg')
library(nnet)
folds <- vfold_cv(data = data_training_pca, v = 10)

lm_mod_pca <- 
  logistic_reg(penalty = 1) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

lm_wf_pca <- workflow() %>%
  add_recipe(data_rec_pca) %>%
  add_model(lm_mod_pca) 

lm_cv_pca <- lm_wf_pca %>%
  fit_resamples(resamples = folds)

# select the best model based on the "accuracy" metric
lm_best_pca <- lm_cv_pca %>%
  select_best(metric = "accuracy")

# to update (or "finalize") your workflow by modifying the line below
lm_final_pca <- 
  finalize_workflow(lm_wf_pca,
                    parameters = lm_best_pca)

lm_fit_pca <- lm_final_pca %>%
  fit(data = data_training_pca)

# fit to all training data
predictions_lm_pca  <- bind_cols(
  data_training_pca,
  predict(object = lm_fit_pca, 
          new_data = data_training_pca),
  predict(object = lm_fit_pca, 
          new_data = data_training_pca, type = "prob"))

select(predictions_lm_pca, in_labor, starts_with(".pred"))

cm_lm_pca <- conf_mat(data = predictions_lm_pca,
               truth = in_labor,
               estimate = .pred_class)
cm_lm_pca
```

## Choose Decision Tree as our model 
```{r}
# fit to testing data
predictions_tree_test_pca <- bind_cols(
  data_testing_pca,
  predict(object = tree_fit_pca, 
          new_data = data_testing_pca),
  predict(object = tree_fit_pca, 
          new_data = data_testing_pca, type = "prob"))

select(predictions_tree_pca, in_labor, starts_with(".pred"))

cm_tree_test_pca <- conf_mat(data = predictions_tree_test_pca,
               truth = in_labor,
               estimate = .pred_class)
cm_tree_test_pca
```